import pandas as pd
import numpy as np


data=pd.read_csv('IOT-temp.csv')
data


data.describe()


import tensorflow as tf
import matplotlib.pyplot as plt


data.groupby('out/in').describe()


# separate between in ds and out ds

ds = data[['noted_date', 'temp', 'out/in']]
in_ds = ds[ds['out/in'] == 'In']

in_ds.plot(
    x='noted_date',
    y='temp',
    figsize=(14, 14)
)

out_ds = ds[ds['out/in'] == 'Out']

out_ds.plot(
    x='noted_date',
    y='temp',
    figsize=(14, 14)
)


def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
    series = tf.expand_dims(series, axis=-1)
    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size + 1))
    ds = ds.shuffle(shuffle_buffer)
    ds = ds.map(lambda w: (w[:-1], w[-1:]))
    return ds.batch(batch_size).prefetch(1)


dataset = out_ds['temp'].astype(float).values

data_shape = dataset.shape[0]
val_split = 0.2
test_split = 0.1

# training split will have 70% of data, validation 20%, test 10%
train_ds = dataset[:int(data_shape*(1-val_split-test_split))]
val_ds = dataset[int(data_shape*(1-val_split-test_split)):int(data_shape*(1-test_split))]
test_ds = dataset[int(data_shape*(1-test_split)):]


# using LSTM to predict for the next 60 data points

train_set = windowed_dataset(train_ds, window_size=60, batch_size=100, shuffle_buffer=1000)
val_set = windowed_dataset(train_ds, window_size=60, batch_size=100, shuffle_buffer=1000)

model = tf.keras.models.Sequential([
  tf.keras.layers.LSTM(60, return_sequences=True),
  tf.keras.layers.LSTM(60),
  tf.keras.layers.Dense(30, activation="relu"),
  tf.keras.layers.Dense(10, activation="relu"),
  tf.keras.layers.Dense(1),
])


## early stopping to keep model simple
es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', 
                                      min_delta=0.0001, 
                                      patience=5, 
                                      verbose=0, 
                                      mode='auto')


LR_START = 0.00001
LR_MAX = 0.0005
LR_MIN = 0.0001
LR_RAMPUP_EPOCHS = 25
LR_SUSTAIN_EPOCHS = 0
LR_EXP_DECAY = .8
EPOCHS = 100

def lrfn(epoch):
    if epoch < LR_RAMPUP_EPOCHS:
        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START
    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:
        lr = LR_MAX
    else:
        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN
    return lr
    
lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)

rng = [i for i in range(EPOCHS)]
y = [lrfn(x) for x in rng]
plt.plot(rng, y)
print("Learning rate schedule: {:.3g} to {:.3g} to {:.3g}".format(y[0], max(y), y[-1]))


optimizer = tf.keras.optimizers.SGD(momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])

history = model.fit(train_set,
                    validation_data=val_set,
                    callbacks = [es_callback, lr_callback],
                    epochs=EPOCHS)


import matplotlib.pyplot as plt

def plot_graphs(history, metric):
    plt.plot(history.history[metric])
    plt.plot(history.history['val_'+metric], '')
    plt.xlabel("Epochs")
    plt.ylabel(metric)
    plt.legend([metric, 'val_'+metric])

plt.figure(figsize=(16, 8))
plt.subplot(1, 2, 1)
plot_graphs(history, 'mae')
plt.subplot(1, 2, 2)
plot_graphs(history, 'loss')
plt.ylim(0, None)


test_set = windowed_dataset(test_ds, window_size=60, batch_size=100, shuffle_buffer=1000)
prediction = model.predict(test_set)


fig, ax = plt.subplots(figsize=(14,14))
ax.plot(
    prediction,
    color='orange',
    label='Prediction'
)
ax.plot(
    test_ds,
    color='blue',
    label='Ground Truth'
)
plt.title('Prediction vs Ground Truth', size=14)
plt.legend()
plt.show()


def moving_average(a, n=10) :
    ret = np.cumsum(a, dtype=float)
    ret[n:] = ret[n:] - ret[:-n]
    return ret[n - 1:] / n


fig, ax = plt.subplots(figsize=(14,14))
ax.plot(
    moving_average(prediction),
    color='orange',
    label='Prediction'
)
ax.plot(
    moving_average(test_ds),
    color='blue',
    label='Ground Truth'
)
plt.title('Moving Average Prediction vs Ground Truth', size=14)
plt.legend()
plt.show()



